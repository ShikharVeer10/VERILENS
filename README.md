# VERILENS

VERILENS is a document processing and retrieval system that implements a RAG (Retrieval-Augmented Generation) pipeline for intelligent document analysis and querying.

## ğŸ¯ Overview

VERILENS provides a robust framework for:
- **Document Ingestion**: Loading and processing PDF and text documents
- **Smart Chunking**: Breaking down large documents into manageable, overlapping chunks for better context preservation
- **Vector Embeddings**: Converting text chunks into vector representations using TF-IDF
- **Intelligent Retrieval**: Finding relevant document chunks based on semantic similarity
- **Answer Generation**: Generating answers with citations using Groq's LLM API
- **Verification**: Optional answer verification to ensure responses are grounded in source documents

## ğŸ—ï¸ Architecture

```
app/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ tools.py           # Agent tools for retrieval
â”‚   â”‚   â””â”€â”€ verilens_agent.py  # Main VeriLens agent
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py          # Central configuration management
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ loader.py          # Document loading from disk
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py      # PDF file processing
â”‚   â”‚   â”œâ”€â”€ chunker.py         # Text chunking with overlap
â”‚   â”‚   â””â”€â”€ indexer.py         # Document indexing
â”‚   â”œâ”€â”€ reason/
â”‚   â”‚   â”œâ”€â”€ generator.py       # Answer generation with LLM
â”‚   â”‚   â””â”€â”€ prompt.py          # System prompts
â”‚   â”œâ”€â”€ retrieve/
â”‚   â”‚   â”œâ”€â”€ embedder.py        # TF-IDF embeddings
â”‚   â”‚   â”œâ”€â”€ retriever.py       # Chunk retrieval
â”‚   â”‚   â””â”€â”€ vector_store.py    # In-memory vector storage
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ document.py        # Document and chunk models
â”‚   â”‚   â”œâ”€â”€ embedding.py       # Embedded chunk models
â”‚   â”‚   â””â”€â”€ response.py        # Response schemas
â”‚   â””â”€â”€ verify/
â”‚       â”œâ”€â”€ base.py            # Verification models
â”‚       â””â”€â”€ verifier.py        # Answer verification
```

## âœ¨ Features

- **PDF Support**: Load and process PDF documents with PyPDF2
- **Configurable Chunking**: Adjustable chunk size and overlap for optimal context retention
- **Groq Integration**: Leverages Llama 3.3 70B via Groq API for fast inference
- **TF-IDF Embeddings**: Efficient local embeddings without external API calls
- **Type Safety**: Built with Pydantic for robust data validation
- **Answer Verification**: Optional verification to ensure answers are grounded in evidence
- **Interactive CLI**: User-friendly command-line interface for document Q&A
- **Modular Design**: Clean separation of concerns for easy maintenance and extension

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- Groq API key (free at [console.groq.com](https://console.groq.com))

### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/VERILENS.git
cd VERILENS
```

2. Create and activate a virtual environment:
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# or
source .venv/bin/activate  # Linux/Mac
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create a `.env` file in the root directory:
```env
GROQ_API_KEY=your_groq_api_key_here
```

### Configuration

The system can be configured via [app/core/core/config.py](app/core/core/config.py):

- `LLM_MODEL`: Language model for generation (default: llama-3.3-70b-versatile)
- `TOP_K`: Number of chunks to retrieve (default: 3)
- `CHUNK_SIZE`: Size of text chunks in characters (default: 500)
- `CHUNK_OVERLAP`: Overlap between consecutive chunks (default: 100)

## ğŸ“š Usage

### Interactive Mode

Run the application and provide a PDF file:

```bash
python run.py
```

Then follow the prompts to:
1. Enter the path to your PDF file
2. Ask questions about the document
3. Get answers with source citations

### Programmatic Usage

```python
from app.core.ingest.pdf_loader import load_pdf
from app.core.ingest.chunker import chunk_document
from app.core.ingest.indexer import index_chunks
from app.core.retrieve.vector_store import VectorStore
from app.core.agent.verilens_agent import VeriLensAgent
from app.core.schemas.document import Document

# Load and process PDF
text = load_pdf("path/to/document.pdf")
document = Document(content=text, source="document.pdf")

# Chunk and index
vector_store = VectorStore()
chunks = chunk_document(document)
index_chunks(chunks, vector_store)

# Create agent and ask questions
agent = VeriLensAgent(vector_store)
answer = agent.answer("What is the main topic of this document?")
print(answer)
```

## ğŸ› ï¸ Tech Stack

- **Pydantic**: Data validation and settings management
- **OpenAI SDK**: API client for Groq compatibility
- **Groq**: Fast LLM inference with Llama 3.3
- **NumPy**: Numerical operations
- **scikit-learn**: TF-IDF vectorization
- **PyPDF2**: PDF text extraction
- **scikit-learn**: Machine learning utilities
- **python-dotenv**: Environment variable management

## ğŸ“ Project Status

Currently in active development. The core document processing pipeline is functional, with ongoing work on:
- Query processing
- Response generation
- Vector similarity search
- API endpoints

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.

## ğŸ“„ License

This project is open source and available under the MIT License.

---

**VERILENS** - Intelligent Document Processing and Retrieval
Contribution test
